{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, copy, random, sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import dataset, utils_CGCD, losses, net\n",
    "from net.resnet import *\n",
    "\n",
    "from models.modelgen import ModelGen, ModelGen_new\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from covmet import ConvNet\n",
    "from edison_functions import compute_euclidean, contrastive_loss, extract_sample\n",
    "torch.manual_seed(1)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDict(dict):\n",
    "    def __init__(self, args):\n",
    "        self.args\n",
    "\n",
    "class BlankClass:\n",
    "    pass\n",
    "\n",
    "args = BlankClass()\n",
    "\n",
    "args.sz_batch  = 512\n",
    "args.nb_epochs = 60\n",
    "args.nb_workers = 8\n",
    "\n",
    "args.lr = 1e-4\n",
    "args.weight_decay = 1e-4\n",
    "args.lr_decay_step = 5\n",
    "args.lr_decay_gamma =  0.5\n",
    "args.warm = 5\n",
    "args.bn_freeze = False \n",
    "args.dataset = 'pamap'   # Dataset \n",
    "only_test_step1 = False            # Just to test the data on Train_1\n",
    "args.model = 'resnet18'        # Model Name\n",
    "window_len = 200\n",
    "\n",
    "args.sz_embedding = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : pamap\n"
     ]
    }
   ],
   "source": [
    "pth_rst = 'CGCD-main/src/result/' + args.dataset\n",
    "os.makedirs(pth_rst, exist_ok=True)\n",
    "pth_rst_exp = 'Saved_Models/Initial/Edison/' + args.dataset + '/' #+ args.model + '_sp_' + str(args.use_split_modlue) + '_gm_' + str(args.use_GM_clustering) + '_' + args.exp\n",
    "os.makedirs(pth_rst_exp, exist_ok=True)\n",
    "\n",
    "print(\"Dataset :\", args.dataset)\n",
    "####\n",
    "\n",
    "pth_dataset = '../datasets'\n",
    "\n",
    "if args.dataset =='wisdm':\n",
    "    pth_dataset = 'HAR_data/Wisdm/'\n",
    "elif args.dataset =='realworld':\n",
    "    pth_dataset = 'HAR_data/realworld/'\n",
    "    nb_classes_now = 8\n",
    "elif args.dataset =='oppo':\n",
    "    pth_dataset = 'HAR_data/oppo/'\n",
    "elif args.dataset =='pamap':\n",
    "    pth_dataset = 'HAR_data/pamap/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11} {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
      "With Embedding\n",
      "No of classes : -> 12\n"
     ]
    }
   ],
   "source": [
    "dset_tr_0 = dataset.load(name=args.dataset, root=pth_dataset, mode='train_0', windowlen= window_len, autoencoderType= None)\n",
    "dlod_tr_0 = torch.utils.data.DataLoader(dset_tr_0, batch_size=args.sz_batch, shuffle=True, num_workers=args.nb_workers, drop_last=True)\n",
    "\n",
    "dset_ev = dataset.load(name=args.dataset, root=pth_dataset, mode='eval_0', windowlen=window_len, autoencoderType= None)\n",
    "dlod_ev = torch.utils.data.DataLoader(dset_ev, batch_size=args.sz_batch, shuffle=False, num_workers=args.nb_workers)\n",
    "\n",
    "dset_test_0 = dataset.load(name=args.dataset, root=pth_dataset, mode='test_0', windowlen=window_len, autoencoderType= None)\n",
    "dlod_test_0 = torch.utils.data.DataLoader(dset_test_0, batch_size=args.sz_batch, shuffle=False, num_workers=args.nb_workers)\n",
    "\n",
    "# nb_classes = dset_test_0.nb_classes()\n",
    "nb_classes = dset_tr_0.nb_classes()\n",
    "\n",
    "# Configuration for the Model\n",
    "if(args.model == 'resnet18'):\n",
    "    cfg = {'weights_path': 'CGCD-main/src/Saved_Models/UK_BioBank_pretrained/mtl_best.mdl', \"use_ssl_weights\" : False, 'conv_freeze': False, 'load_finetuned_mtl': False,\n",
    "        'checkpoint_name' :'', 'epoch_len': 2, 'output_size': '', 'embedding_dim': args.sz_embedding, 'bottleneck_dim': None,\n",
    "            'output_size':nb_classes,'weight_norm_dim': ''}\n",
    "\n",
    "    model = ModelGen_new(cfg).create_model().to(device)\n",
    "\n",
    "if(args.model == 'harnet'):\n",
    "    repo = 'OxWearables/ssl-wearables'\n",
    "    model = torch.hub.load(repo, 'harnet5', class_num=nb_classes, pretrained=True).to(device)\n",
    "    del model.classifier\n",
    "    model.embedding = nn.Sequential(nn.Linear(model.feature_extractor.layer5[0].out_channels,args.sz_embedding)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_tr_0.xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id =0\n",
    "param_groups = [\n",
    "    {'params': list(set(model.parameters()).difference(set(model.embedding.parameters()))) if gpu_id != -1 else list(set(model.module.parameters()).difference(set(model.module.model.embedding.parameters())))},\n",
    "    {'params': model.embedding.parameters() if gpu_id != -1 else model.embedding.parameters(), 'lr': float(args.lr) * 1},]\n",
    "\n",
    "    # param_groups.append({'params': criterion_pa.parameters(), 'lr': float(args.lr)*100 })\n",
    "opt_pa = torch.optim.AdamW(param_groups, lr=float(args.lr), weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 1\n",
    "step =0\n",
    "pth_pth = '{}{}_{}_best_windowlen_{}_embedding_size_{}_version_{}_step_{}.pth'.format(pth_rst_exp, args.dataset, args.model, window_len, args.sz_embedding, version, step)\n",
    "checkpoint = torch.load(pth_pth)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_pa_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_prototypes = np.load('{}{}_{}_prototypes_windowlen_{}_embedding_size_{}_version_{}_step_{}.npy'.format(pth_rst_exp, args.dataset, args.model, window_len, args.sz_embedding, version, step), allow_pickle= True)\n",
    "\n",
    "trained_prototypes_dict = dict()\n",
    "for loaded_prototype in loaded_prototypes:\n",
    "    trained_prototypes_dict[int(loaded_prototype[0])] = loaded_prototype[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_proto_trained = torch.from_numpy(np.array(list(trained_prototypes_dict.values()))).float().to(device)\n",
    "\n",
    "# Calculating Test Accuracy\n",
    "# with torch.no_grad():\n",
    "#     total_accuracy_test, n_steps = 0, 0\n",
    "#     for x, y, z in dlod_test_0:\n",
    "#         embeddings_test = model(x.to(device))\n",
    "#         dists_test = compute_euclidean(embeddings_test,z_proto_trained)\n",
    "#         log_p_test = F.softmax(-dists_test,dim=1)\n",
    "#         test_accuracy = accuracy_score(torch.argmax(log_p_test, dim = 1).to('cpu').detach().numpy(), y.to('cpu').detach().numpy())\n",
    "#         total_accuracy_test += test_accuracy\n",
    "#         n_steps +=1\n",
    "\n",
    "#     print(\"Test Accuracy {:.2f} %\".format(total_accuracy_test/n_steps))\n",
    "\n",
    "# Calculating Train Accuracy\n",
    "# with torch.no_grad():\n",
    "#     total_accuracy_train, n_steps = 0, 0\n",
    "#     all_embeddings = []\n",
    "#     all_ys = []\n",
    "#     for x, y, z in dlod_tr_0:\n",
    "#         embeddings_train = model(x.to(device))\n",
    "#         if(len(all_embeddings)==0):\n",
    "#             all_embeddings = embeddings_train\n",
    "#             all_ys = y\n",
    "#         else:\n",
    "#             all_embeddings = torch.concatenate((all_embeddings, embeddings_train), axis =0)\n",
    "#             all_ys = torch.concatenate((all_ys, y), axis =0)\n",
    "\n",
    "\n",
    "#         dists_train = compute_euclidean(embeddings_train,z_proto_trained)\n",
    "#         log_p_train = F.softmax(-dists_train,dim=1)\n",
    "#         train_accuracy = accuracy_score(torch.argmax(log_p_train, dim = 1).to('cpu').detach().numpy(), y.to('cpu').detach().numpy())\n",
    "#         total_accuracy_train += train_accuracy\n",
    "#         n_steps +=1\n",
    "\n",
    "#     print(\"Train Accuracy {:.2f} %\".format(total_accuracy_train/n_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17} {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}\n"
     ]
    }
   ],
   "source": [
    "dset_tr_now_md = 'train_1' # 'train_2'\n",
    "dset_ev_now_md = 'eval_1' # 'eval_2'\n",
    "\n",
    "dset_tr_now = dataset.load(name=args.dataset, root=pth_dataset, mode=dset_tr_now_md,windowlen= window_len, autoencoderType= None)\n",
    "dset_ev_now = dataset.load(name=args.dataset, root=pth_dataset, mode=dset_ev_now_md,windowlen= window_len, autoencoderType= None)\n",
    "dset_test = dataset.load(name=args.dataset, root=pth_dataset, mode='test_1', windowlen= window_len, autoencoderType= None)\n",
    "\n",
    "dlod_tr_now = torch.utils.data.DataLoader(dset_tr_now, batch_size=args.sz_batch, shuffle=True, num_workers=args.nb_workers)\n",
    "dlod_ev_now = torch.utils.data.DataLoader(dset_ev_now, batch_size=args.sz_batch, shuffle=False, num_workers=args.nb_workers)\n",
    "\n",
    "dlod_test = torch.utils.data.DataLoader(dset_test, batch_size=args.sz_batch, shuffle=False, num_workers=args.nb_workers)\n",
    "\n",
    "nb_classes_now = dset_tr_now.nb_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 Test Dataset on Stage 1 trained model, Seen Accuracy 0.80  Unseen Accuracy  0.00\n"
     ]
    }
   ],
   "source": [
    "# Prediction accuracy on Stage 2 test dataset on Stage 1 Model.\n",
    "\n",
    "predicted_y = []\n",
    "actual_y = []\n",
    "with torch.no_grad():\n",
    "    z_proto_test = torch.from_numpy(np.array(list(trained_prototypes_dict.values()))).float().to(device)\n",
    "    for x_test, y_test, z_test in dlod_test_0:\n",
    "        embeddings_val = model(x_test.to(device))\n",
    "        dists_val = compute_euclidean(embeddings_val,z_proto_test)\n",
    "        log_p_val = F.softmax(-dists_val,dim=1)\n",
    "        if(len(predicted_y)==0):\n",
    "            predicted_y = torch.argmax(log_p_val, dim = 1).to('cpu').detach().numpy()\n",
    "            actual_y = y_test.to('cpu').detach().numpy()\n",
    "        else:\n",
    "            predicted_y = np.concatenate((predicted_y, torch.argmax(log_p_val, dim = 1).to('cpu').detach().numpy()))\n",
    "            actual_y = np.concatenate((actual_y,y_test.to('cpu').detach().numpy() ))\n",
    "        \n",
    "    \n",
    "\n",
    "    y_test = torch.tensor(actual_y).type(torch.LongTensor)\n",
    "    predicted_y = torch.tensor(predicted_y).type(torch.LongTensor)\n",
    "\n",
    "    seen_classes = torch.where(y_test < nb_classes, 1, 0)\n",
    "    seen_classes_idx = torch.nonzero(seen_classes)\n",
    "    unseen_classes = torch.where(y_test >= nb_classes, 1, 0)\n",
    "    unseen_classes_idx = torch.nonzero(unseen_classes)\n",
    "\n",
    "    if(seen_classes.sum().item()>0):\n",
    "        acc_o = accuracy_score(y_test[seen_classes_idx], predicted_y[seen_classes_idx])\n",
    "    else:\n",
    "        acc_o =0\n",
    "    if(unseen_classes.sum().item()>0):\n",
    "        acc_n = accuracy_score(y_test[unseen_classes_idx], predicted_y[unseen_classes_idx])\n",
    "    else:\n",
    "        acc_n =0\n",
    "\n",
    "    \n",
    "    print(\"Stage 2 Test Dataset on Stage 1 trained model, Seen Accuracy {:.2f}  Unseen Accuracy  {:.2f}\".\n",
    "          format(acc_o, acc_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(dataset, index, index_target=None, target=None):\n",
    "    dataset_ = copy.deepcopy(dataset)\n",
    "\n",
    "    if target is not None:\n",
    "        for i, v in enumerate(index_target):\n",
    "            dataset_.ys[v] = target[i]\n",
    "\n",
    "    for i, v in enumerate(index):\n",
    "        # print(\"Index \",index, \"Dataset.I\",dataset_.I)\n",
    "        j = v - i    # We seperate i because as we pop a element outside the array moves towards left and its size decreases\n",
    "        dataset_.I.pop(j)\n",
    "        dataset_.ys.pop(j)\n",
    "        # dataset_.im_paths.pop(j)\n",
    "    return dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the old indices from the dataloader.\n",
    "old_indices = []\n",
    "for idx,y in enumerate(dset_tr_now.ys):\n",
    "    if(y < nb_classes):\n",
    "        old_indices.append(idx)\n",
    "\n",
    "\n",
    "dset_tr_only_new = generate_dataset(dset_tr_now, old_indices)\n",
    "dlod_tr_only_new = torch.utils.data.DataLoader(dset_tr_only_new, batch_size=args.sz_batch, shuffle=True, num_workers=args.nb_workers)\n",
    "# np.unique(dset_tr_o.ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New classes: [2, 9, 7, 3, 0, 5, 10, 1, 6, 4, 8, 11], Old Classes: dict_keys([])\n",
      " Updated memory size for each old class: 6 [Train size: {11: 6, 4: 6, 8: 6, 7: 6, 5: 6, 9: 6, 1: 6, 6: 6, 2: 6, 0: 6, 3: 6, 10: 6}\n"
     ]
    }
   ],
   "source": [
    "from replay_memory import *\n",
    "replay_size = 6\n",
    "\n",
    "replay_buffer = ReplayMemory(replay_size)\n",
    "replay_buffer.update((np.array(dset_tr_0.xs), np.array(dset_tr_0.ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_now = copy.deepcopy(model)\n",
    "model_now = model_now.to(device)\n",
    "opt_pa_now = torch.optim.AdamW(model_now.parameters(), lr=float(args.lr), weight_decay=args.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:303: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 CE Loss 0.28710 Constastive Loss 5.78314\n",
      "==> Evaluation..\n",
      "Valid Accuracies Seen 0.50, Unseen 0.38, Overall 0.40\n",
      "Got Better Model with  Seen 0.50 ,  Unseen Accuracies 0.38,  Overalll 0.40 and  Average as 0.43 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m total_ce_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     35\u001b[0m nsteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdlod_tr_only_new\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_map_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_classes_now\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcluded_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Dhruv\\anaconda3\\envs\\CLHAR\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from edison_functions import compute_euclidean, contrastive_loss, extract_sample\n",
    "from sklearn import utils\n",
    "\n",
    "step1_prototypes_dict = copy.deepcopy(trained_prototypes_dict)\n",
    "counters = dict()\n",
    "best_weighted_acc = 0\n",
    "args.gpu_id = 0\n",
    "for epoch in range(0,1):  #args.nb_epochs\n",
    "    \n",
    "    model_now.train()\n",
    "    ####\n",
    "    bn_freeze = args.bn_freeze\n",
    "    if bn_freeze:\n",
    "        modules = model_now.modules() if args.gpu_id != -1 else model_now.module.model.modules()\n",
    "        for m in modules:\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "    if args.warm > 0:\n",
    "        # Early Stopping to remain one during the warnmp\n",
    "        if args.gpu_id != -1:\n",
    "            unfreeze_model_param = list(model_now.embedding.parameters()) \n",
    "        else:\n",
    "            unfreeze_model_param = list(model_now.module.model.embedding.parameters()) \n",
    "\n",
    "        if epoch == 0:\n",
    "            for param in list(set(model_now.parameters()).difference(set(unfreeze_model_param))):\n",
    "                param.requires_grad = False\n",
    "        if epoch == args.warm:\n",
    "            for param in list(set(model_now.parameters()).difference(set(unfreeze_model_param))):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    \n",
    "    total_contrastive_loss = 0\n",
    "    total_ce_loss = 0\n",
    "    nsteps = 0\n",
    "    for x, y, z in dlod_tr_only_new:\n",
    "        \n",
    "        y_map_labels = tf.keras.utils.to_categorical(y, num_classes=nb_classes_now)\n",
    "\n",
    "        excluded_classes = []\n",
    "        replay_set, replay_map_labels = replay_buffer.exemplar_train(excluded_classes)\n",
    "\n",
    "        replay_set = torch.from_numpy(np.array(replay_set)).float()\n",
    "        replay_set = torch.Tensor(np.transpose(replay_set, (0,2,1)))\n",
    "        \n",
    "        replay_map_labels_temp = torch.Tensor(replay_map_labels)  # Storing the non-binarized form\n",
    "        replay_map_labels = torch.Tensor(replay_map_labels)\n",
    "        replay_map_labels = tf.keras.utils.to_categorical(replay_map_labels, num_classes=nb_classes_now)\n",
    "\n",
    "        query_set_x = torch.cat((x,replay_set),0)  # Merging old and new class elements\n",
    "        query_set_labels = torch.cat((torch.Tensor(y_map_labels),torch.Tensor(replay_map_labels)),0).to(device)\n",
    "\n",
    "    \n",
    "        x_support_embeddings = model_now(x.to(device))\n",
    "        x_query_embeddings = model_now(query_set_x.to(device))\n",
    "\n",
    "        # Update/Create Prototypes of New Classes\n",
    "        classes = np.sort(np.unique(y))\n",
    "        for c in classes:\n",
    "            if c in step1_prototypes_dict.keys():\n",
    "                p_mean_old = copy.deepcopy(np.array(step1_prototypes_dict[c]).astype(np.float64))\n",
    "                # print(c, np.shape(p_mean_old), p_mean_old)\n",
    "                new_count = len(np.array(x_support_embeddings.data.cpu().numpy()[y==c]))\n",
    "                #print(np.shape(p_mean_old), np.shape(np.array(X)))\n",
    "                \n",
    "                p_mean = float((counters[c]/(1.*(counters[c]+new_count))))*p_mean_old + np.sum(np.array(x_support_embeddings.data.cpu().numpy())[y==c],axis=0)/(counters[c]+new_count)\n",
    "                #print(p_mean, p_mean_old)\n",
    "                #sys.exit()\n",
    "                step1_prototypes_dict[c] = copy.deepcopy(p_mean.flatten().astype(np.float64))\n",
    "                counters[c] += new_count\n",
    "                #print('old: ',c, p_mean_old, self.prototypes[c])\n",
    "\n",
    "            else:\n",
    "                # print('new: ', self.prototypes.keys(), c)\n",
    "                p_mean = np.mean(x_support_embeddings.data.cpu().numpy()[y==c],axis=0)\n",
    "\n",
    "                #print(np.shape(X[y==c]))\n",
    "                step1_prototypes_dict[c] = copy.deepcopy(p_mean.flatten())\n",
    "                counters[c] = len(x_support_embeddings.data.cpu().numpy()[y==c])\n",
    "\n",
    "        # Calculate Distances.\n",
    "        dists = torch.ones((len(x_query_embeddings),nb_classes_now))*float('inf')\n",
    "        dists = dists.float().to(device)\n",
    "        #print(\"CURRENT CLASSES IN PROTOTYPE MEMORY: \", list(self.memory.prototypes.keys()))\n",
    "        for c in step1_prototypes_dict.keys():\n",
    "\n",
    "            z_proto = torch.from_numpy(step1_prototypes_dict[c][None,:]).float().to(device)# Adding None just increases the shape from (128,) -> (1,128)\n",
    "            dist = compute_euclidean(x_query_embeddings,z_proto)\n",
    "            #print(np.shape(dist))\n",
    "            dists[:,c] = torch.squeeze(dist)\n",
    "\n",
    "        # Calculate the Loss.\n",
    "        log_p = F.softmax(-dists,dim=1)\n",
    "        ce_loss = F.binary_cross_entropy(log_p, query_set_labels) \n",
    "\n",
    "        contrastive_losses  = contrastive_loss(x_query_embeddings, query_set_labels,step1_prototypes_dict, balance=True)\n",
    "\n",
    "        loss = 10*ce_loss + contrastive_losses\n",
    "        \n",
    "        total_contrastive_loss += contrastive_losses.item()\n",
    "        total_ce_loss += ce_loss.item() \n",
    "        nsteps +=1 \n",
    "        \n",
    "        \n",
    "        opt_pa_now.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_pa_now.step()\n",
    "        \n",
    "        # Online Training.\n",
    "        online_epochs = 1\n",
    "        total_online_training_ce_loss = 0\n",
    "        total_online_training_contrastive_loss = 0\n",
    "        for i in range(1,online_epochs):\n",
    "            query_set1, query_map_labels1 = utils.shuffle(query_set_x,query_set_labels, random_state=i)\n",
    "            x_query_embeddings_1 = model_now(query_set1.to(device))\n",
    "\n",
    "            dists_1 = torch.ones((len(x_query_embeddings_1),nb_classes_now))*float('inf')\n",
    "            \n",
    "            dists_1 = dists_1.float().to(device)\n",
    "            #print(\"CURRENT CLASSES IN PROTOTYPE MEMORY: \", list(self.memory.prototypes.keys()))\n",
    "            for c in step1_prototypes_dict.keys():\n",
    "\n",
    "                z_proto_1 = torch.from_numpy(step1_prototypes_dict[c][None,:]).float().to(device)# Adding None just increases the shape from (128,) -> (1,128)\n",
    "                dist_1 = compute_euclidean(x_query_embeddings_1,z_proto_1)\n",
    "                #print(np.shape(dist))\n",
    "                dists_1[:,c] = torch.squeeze(dist_1)\n",
    "                \n",
    "            log_p_1 = F.softmax(-dists_1,dim=1)\n",
    "\n",
    "            ce_loss1 = F.binary_cross_entropy(log_p_1, query_map_labels1)\n",
    "            \n",
    "            contrastive_losses = contrastive_loss(x_query_embeddings_1, query_map_labels1, step1_prototypes_dict, balance=True)  \n",
    "            loss = 10*ce_loss1 + contrastive_losses\n",
    "            opt_pa_now.zero_grad()\n",
    "            loss.backward()\n",
    "            opt_pa_now.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        # Updating the prototypes of the seen/base classes\n",
    "    model_now.eval()\n",
    "    if len(replay_set) > 0:\n",
    "        \n",
    "        base_new_prototypes = dict()\n",
    "        base_new_counters = dict()\n",
    "        #print(classes)\n",
    "        replay_set_embeddings = model_now(replay_set.to(device))\n",
    "        old_classes = np.unique(replay_map_labels_temp.data.cpu())\n",
    "        for c in old_classes:\n",
    "            p_mean = replay_set_embeddings[replay_map_labels_temp.data.cpu()==c].mean(0)\n",
    "            #print(np.shape(X[y==c]))\n",
    "            base_new_prototypes[c] = copy.deepcopy(list(p_mean.data.cpu().numpy().flatten()))\n",
    "            base_new_counters[c] = len(replay_set_embeddings[replay_map_labels_temp.data.cpu()==c])\n",
    "\n",
    "        momentum = 0.5\n",
    "        for c in base_new_prototypes.keys():\n",
    "            step1_prototypes_dict[c] = copy.deepcopy((momentum*np.array(step1_prototypes_dict[c]).astype(np.float64) + (1.-momentum)*np.array(base_new_prototypes[c]).astype(np.float64)).flatten().astype(np.float64))\n",
    "\n",
    "\n",
    "    print(\"Epoch {} CE Loss {:.5f} Constastive Loss {:.5f}\".format(epoch, total_ce_loss/nsteps, total_contrastive_loss/nsteps ))\n",
    "\n",
    "\n",
    "    print('==> Evaluation..')\n",
    "    \n",
    "    predicted_y = []\n",
    "    actual_y = []\n",
    "    with torch.no_grad():\n",
    "        z_proto_val = torch.from_numpy(np.array(list(step1_prototypes_dict.values()))).float().to(device)\n",
    "        for x_val, y_val, z_val in dlod_ev_now:\n",
    "            embeddings_val = model_now(x_val.to(device))\n",
    "            dists_val = compute_euclidean(embeddings_val,z_proto_val)\n",
    "            log_p_val = F.softmax(-dists_val,dim=1)\n",
    "            if(len(predicted_y)==0):\n",
    "                predicted_y = torch.argmax(log_p_val, dim = 1).to('cpu').detach().numpy()\n",
    "                actual_y = y_val.to('cpu').detach().numpy()\n",
    "            else:\n",
    "                predicted_y = np.concatenate((predicted_y, torch.argmax(log_p_val, dim = 1).to('cpu').detach().numpy()))\n",
    "                actual_y = np.concatenate((actual_y,y_val.to('cpu').detach().numpy() ))\n",
    "            \n",
    "        \n",
    "\n",
    "        y_val = torch.tensor(actual_y).type(torch.LongTensor)\n",
    "        predicted_y = torch.tensor(predicted_y).type(torch.LongTensor)\n",
    "\n",
    "        seen_classes = torch.where(y_val < nb_classes, 1, 0)\n",
    "        seen_classes_idx = torch.nonzero(seen_classes)\n",
    "        unseen_classes = torch.where(y_val >= nb_classes, 1, 0)\n",
    "        unseen_classes_idx = torch.nonzero(unseen_classes)\n",
    "\n",
    "        if(seen_classes.sum().item()>0):\n",
    "            acc_o = accuracy_score(y_val[seen_classes_idx], predicted_y[seen_classes_idx])\n",
    "        else:\n",
    "            acc_o =0\n",
    "        if(unseen_classes.sum().item()>0):\n",
    "            acc_n = accuracy_score(y_val[unseen_classes_idx], predicted_y[unseen_classes_idx])\n",
    "        else:\n",
    "            acc_n =0\n",
    "                    \n",
    "        acc_a = accuracy_score(y_val, predicted_y)\n",
    "\n",
    "        print(\"Valid Accuracies Seen {:.2f}, Unseen {:.2f}, Overall {:.2f}\".format(acc_o, acc_n, acc_a))\n",
    "\n",
    "\n",
    "        step = 2\n",
    "        if((acc_o + acc_n + acc_a)/3 > best_weighted_acc):\n",
    "            best_seen = acc_o\n",
    "            best_unseen = acc_n\n",
    "            best_overall = acc_a\n",
    "            best_weighted_acc = (best_seen + best_unseen + best_overall)/3\n",
    "            es_count = 0\n",
    "            print(\"Got Better Model with  Seen {:.2f} ,  Unseen Accuracies {:.2f},  Overalll {:.2f} and  Average as {:.2f} \".format( best_seen,best_unseen, best_overall,best_weighted_acc))\n",
    "            # torch.save({'model_pa_state_dict': model_now.state_dict(), 'proxies_param': criterion_pa_now.proxies}, '{}{}_{}_model_last_windowlen_{}_sz_embedding_{}_alpha{}_mrg_{}_step_{}_epoch_{}.pth'.format(pth_rst_exp, args.dataset, args.model,window_len, args.sz_embedding, args.alpha, args.mrg, str(step), epoch))\n",
    "        else:                                                                                                     \n",
    "            es_count +=1 \n",
    "            print(\"Early Stopping Count \", es_count)\n",
    "            \n",
    "        if(epoch< args.warm):\n",
    "            es_count =0    # If we are having warmup then no early stopping\n",
    "        \n",
    "        if(es_count ==10):\n",
    "            \n",
    "            print(\"Best  Valid Accuracies Seen {:.2f} , and Unseen {:.2f},  Overall {:.2f}, Average {:.2f} \".format( best_seen, best_unseen, best_overall, best_weighted_acc))\n",
    "            print(\"Early Stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ys = all_ys.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pylab as plt\n",
    "# plt.figure(figsize=(10,10))\n",
    "# cm = plt.get_cmap('gist_rainbow')\n",
    "# NUM_COLORS = len(trained_prototypes_dict.keys())\n",
    "\n",
    "# colors = [cm((1.*i)/NUM_COLORS) for i in np.arange(NUM_COLORS)]\n",
    "# markers=['.',  'x', 'h','1']\n",
    "\n",
    "# keys = trained_prototypes_dict.keys()\n",
    "# prototypes_pca[0]\n",
    "\n",
    "\n",
    "# for k in keys:\n",
    "#     plt.scatter(prototypes_pca[k][0], prototypes_pca[k][1], marker = 'o')\n",
    "#     plt.scatter(emb_pca[np.array(all_ys) == k][:,0] , emb_pca[np.array(all_ys) == k][:,1], marker = 'o')\n",
    "\n",
    "#     plt.annotate(k, (prototypes_pca[k,0], prototypes_pca[k,1]),\n",
    "#                  horizontalalignment='center',\n",
    "#                  verticalalignment='center',\n",
    "#                  size=10, weight='bold',rotation=45,\n",
    "#                  color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
